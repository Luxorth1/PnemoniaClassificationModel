{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 4 Project | Image Classification Algorithm | X-Ray Imaging to Detect Pneumonia Case\n",
    "\n",
    "#### Goal\n",
    "\n",
    "The goal is to create a machine learning algorithm that will successfully classify images into 2 categories.\n",
    "\n",
    "* Positive for Pneumonia\n",
    "* Negative for Pneumonia\n",
    "\n",
    "The metric of success for this will be a high recall. This is due to the fact we want to reduce the number of False Negatives that are produced. We want to make sure we limit the amount of cases that are actually a pnemonia case, but labeled as healthy.\n",
    "\n",
    "#### Methodology\n",
    "\n",
    "The methodology that will be used for this project will be the OSEMN Methodology. I will outline the methodology below.\n",
    "\n",
    "* Obtain: Gather data from relevant sources\n",
    "* Scrub: Clean data to formats that machine understands\n",
    "* Explore: Find significant patterns and trends using statistical methods\n",
    "* Model: Construct models to predict and forecast\n",
    "* iNterpret: Put results into good use\n",
    "\n",
    "#### Data\n",
    "\n",
    "This will be our Obtain step in our OSEMN as we did not need to do much data mining for this data set.\n",
    "\n",
    "Our data was obtained from [Here](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia) which is a dataset of thousands of chest x-ray images from both patients who have pnemonia and who do not. This labeled data will allow us to create a classification machine in order to determine whether a patient has a case of pnemonia based of a chest x-ray.\n",
    "\n",
    "A larger set of the same data can be found [Here](https://data.mendeley.com/datasets/rscbjbr9sj/3). Due to technical limitations and the fact that there is no funds for this project we will not be using distributed networks to run this project, which limits the amount of data we can realistically work with while maintaining feasibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing all neccessary libraries\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import datetime\n",
    "from keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Scrub\n",
    "\n",
    "Here we will load the data, and begin to format it into the required format for our machine to understand it. \n",
    "\n",
    "First we need to load our images in order to begin processing our images down to the proper resolution, and begin creating our matrices for modeling.\n",
    "\n",
    "We will also be timing our entire notebook to get a better sense of how long this would take beginning to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will instance 'current time' this will allow us to see how long the whole notebook takes\n",
    "start_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will begin to load in our data into 3 separate categories. \n",
    "\n",
    "* Training\n",
    "* Validation\n",
    "* Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#determine file paths\n",
    "train_path = '../data/train'\n",
    "test_path = '../data/test'\n",
    "val_path = '../data/val'\n",
    "#instance ImageDataGenerator for rescaling\n",
    "train_IDG = ImageDataGenerator(rescale=1./255)\n",
    "test_IDG = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# use our IDG to load and scale images\n",
    "\n",
    "train_gen = train_IDG.flow_from_directory(train_path, target_size=(150,150), batch_size=20, class_mode='binary')\n",
    "\n",
    "val_gen = test_IDG.flow_from_directory(val_path, target_size = (150,150), batch_size = 20, class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded our train and validation data we will begin to explore this data below. Once we have explored the data we will begin to create a baseline model, tune this model, then create a reusable pipeline to carryout or steps easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Explore\n",
    "\n",
    "This stage we will take a look into our data and see if we can notice anything. However the difficulty we will have here is that our data is in an image format, it could prove difficult to apply proper EDA to this data set. However, the main goal here is to express how it can prove difficult, and in some cases impossible to identify a case of pnemonia with the naked eye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Model\n",
    "\n",
    "This is where we get into the meat and potatoes of our analysis. We will begin to test different algorithms in order to maximize the performance of our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### iNterpret\n",
    "\n",
    "Here we will begin to take a look ar our results. Understand what they mean, and how we can apply our outcome to larger datasets, and begin to look into productionizing our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
